{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[자연어]텍스트_분석.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdL3qak4QwkufEoS4oUo2t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ovozzx/Deep_Learning/blob/master/%5B%EC%9E%90%EC%97%B0%EC%96%B4%5D%ED%85%8D%EC%8A%A4%ED%8A%B8_%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) NLP \n",
        "→ 기계 번역, 자동 질의응답 시스템\n",
        "\n",
        "## 2) 텍스트 분석\n",
        "→ 텍스트 분류, 감성 분석, 텍스트 요약, 텍스트 군집화\n",
        "\n",
        "## 3) 텍스트 → 피처 벡터화(피처, 빈도 수) : BOW, Word2Vec\n",
        "\n",
        "## 4) 텍스트 분석 프로세스 \n",
        "(1) 텍스트 전처리(클렌징, 대소문자, 토큰화, Stop word, 어근 추출 등) → (2) 피처 벡터화/추출 → (3) 머신러닝 모델링/학습/예측/평가\n"
      ],
      "metadata": {
        "id": "Rd89i7DZF2Qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 텍스트 전처리\n",
        "---\n",
        "\n",
        "-  클렌징 : 불필요한 문자, 기호 제거 ex) HTML, XML, 특정 기호 등\n",
        "- 토큰화 : 문장 or 단어 분리\n",
        "- 스톱 워드(의미 없는 단어) 제거\n",
        "- Stemming & Lemmatization\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "svx4Az6oH_lf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gCcVI0uFyut",
        "outputId": "34b3abd4-249f-4381-d804-313031d506d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "<class 'list'> 3\n",
            "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
          ]
        }
      ],
      "source": [
        "# 문장 토큰화 : 마침표, 개행문자 등으로 분리\n",
        "\n",
        "from nltk import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
        "               You can see it out your window or on your television. \\\n",
        "               You feel it when you go to work, or go to church or pay your taxes.'\n",
        "sentences = sent_tokenize(text=text_sample)\n",
        "print(type(sentences),len(sentences))\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 토큰화 : 공백, 콤마, 마침표, 개행문자 등으로 분리\n",
        "# Bag of Word와 같이 단어의 순서가 중요하지 않은 경우\n",
        "\n",
        "\n",
        "\n",
        "from nltk import word_tokenize\n",
        "\n",
        "sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
        "words = word_tokenize(sentence)\n",
        "print(type(words), len(words))\n",
        "print(words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVq4K9dCKIWK",
        "outputId": "2befe3a6-ffa1-4f8a-f9c6-79d382159f5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 15\n",
            "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s2R7Ww_PKlw9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}